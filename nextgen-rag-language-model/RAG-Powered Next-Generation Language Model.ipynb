{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG9RLduTmZr2",
        "outputId": "7cc90572-eb0f-4c93-d516-71cac1a0d394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in d:\\rag\\venv\\lib\\site-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (0.2.34)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (0.1.101)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\rag\\venv\\lib\\site-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\rag\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\rag\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\rag\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\rag\\venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in d:\\rag\\venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\rag\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\rag\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\rag\\venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\rag\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: anyio in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\rag\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\rag\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in d:\\rag\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\rag\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtr85qlzndvi",
        "outputId": "a0de05c3-7630-4a11-c957-6a843a06e143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in d:\\rag\\venv\\lib\\site-packages (4.3.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H2Co1LixkCkb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"NLP.pdf\")\n",
        "data = loader.load()  # entire PDF is loaded as a single Document\n",
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tEtBig8kDRl",
        "outputId": "ae8f61a9-b6e9-47ac-c8b0-68f834afa483"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkCA5qwPkDV5",
        "outputId": "44991ae7-ae33-4857-b276-0add1244b13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of documents:  96\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# split data\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "docs = text_splitter.split_documents(data)\n",
        "\n",
        "\n",
        "print(\"Total number of documents: \",len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOUK7fwakDZP",
        "outputId": "10b783e1-df85-4af7-e969-1b27be6040e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'yolov9_paper.pdf', 'page': 1}, page_content='target task, it also overcomes the problems encountered by\\nmask modeling. The proposed PGI mechanism can be ap-\\nplied to deep neural networks of various sizes and is more\\ngeneral than the deep supervision mechanism, which is only\\nsuitable for very deep neural networks.\\nIn this paper, we also designed generalized ELAN\\n(GELAN) based on ELAN [65], the design of GELAN si-\\nmultaneously takes into account the number of parameters,\\ncomputational complexity, accuracy and inference speed.\\nThis design allows users to arbitrarily choose appropriate\\ncomputational blocks for different inference devices. We\\ncombined the proposed PGI and GELAN, and then de-\\nsigned a new generation of YOLO series object detection\\nsystem, which we call YOLOv9. We used the MS COCO\\ndataset to conduct experiments, and the experimental results\\nverified that our proposed YOLOv9 achieved the top perfor-\\nmance in all comparisons.\\nWe summarize the contributions of this paper as follows:')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoR5B6TloHA-",
        "outputId": "eaca6660-cd62-4b56-e160-42b975ebad6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-google-genai in d:\\rag\\venv\\lib\\site-packages (1.0.10)\n",
            "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in d:\\rag\\venv\\lib\\site-packages (from langchain-google-genai) (0.7.2)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in d:\\rag\\venv\\lib\\site-packages (from langchain-google-genai) (0.2.34)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.142.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.34.0)\n",
            "Requirement already satisfied: protobuf in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.25.4)\n",
            "Requirement already satisfied: pydantic in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in d:\\rag\\venv\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\rag\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.1.101)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in d:\\rag\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.2.33->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\rag\\venv\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\rag\\venv\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\rag\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\rag\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\rag\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\rag\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\rag\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\rag\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\rag\\venv\\lib\\site-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in d:\\rag\\venv\\lib\\site-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.20.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\rag\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\rag\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\rag\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: colorama in d:\\rag\\venv\\lib\\site-packages (from tqdm->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.4.6)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\rag\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.65.5)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\rag\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\rag\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: anyio in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (4.4.0)\n",
            "Requirement already satisfied: certifi in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.0.5)\n",
            "Requirement already satisfied: idna in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (3.7)\n",
            "Requirement already satisfied: sniffio in d:\\rag\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\rag\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\rag\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\rag\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP3Zjgs7oOB0",
        "outputId": "01f16de2-594b-463b-c7dd-053520f2e6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in d:\\rag\\venv\\lib\\site-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "t9H399SgkDcl",
        "outputId": "a1c18e93-159a-4d38-87a3-0faee8bf4f9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Rag\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.05168594419956207,\n",
              " -0.030764883384108543,\n",
              " -0.03062233328819275,\n",
              " -0.02802734449505806,\n",
              " 0.01813092641532421]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "#Get an API key:\n",
        "# Head to https://ai.google.dev/gemini-api/docs/api-key to generate a Google AI API key. Paste in .env file\n",
        "\n",
        "# Embedding models: https://python.langchain.com/v0.1/docs/integrations/text_embedding/\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[:5]\n",
        "#vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in d:\\rag\\venv\\lib\\site-packages (from chromadb) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.5-cp312-cp312-win_amd64.whl.metadata (262 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Using cached fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in d:\\rag\\venv\\lib\\site-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-3.5.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\rag\\venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.19.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Using cached tokenizers-0.20.0-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests>=2.28 in d:\\rag\\venv\\lib\\site-packages (from chromadb) (2.32.3)\n",
            "  Using cached chromadb-0.5.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.5.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.23-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.21-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.20-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.19-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached chromadb-0.4.17-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Using cached chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pydantic<2.0,>=1.9 (from chromadb)\n",
            "  Using cached pydantic-1.10.17-cp312-cp312-win_amd64.whl.metadata (153 kB)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.4.11-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached chromadb-0.4.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached chromadb-0.4.9-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Using cached chromadb-0.4.8-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.4.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.4.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.4.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.4.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pandas>=1.3 (from chromadb)\n",
            "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.4.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.4.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.3.29-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Using cached chromadb-0.3.27-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pydantic==1.9 (from chromadb)\n",
            "  Using cached pydantic-1.9.0-py3-none-any.whl.metadata (121 kB)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.3.26-py3-none-any.whl.metadata (6.8 kB)\n",
            "  Using cached chromadb-0.3.25-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Using cached chromadb-0.3.23-py3-none-any.whl.metadata (6.3 kB)\n",
            "  Using cached chromadb-0.3.22-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Using cached chromadb-0.3.21-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.20-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.18-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.17-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.16-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.14-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.13-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.12-py3-none-any.whl.metadata (5.7 kB)\n",
            "  Using cached chromadb-0.3.11-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Using cached chromadb-0.3.10-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Using cached chromadb-0.3.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Using cached chromadb-0.3.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.6-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Using cached chromadb-0.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "\n",
            "The conflict is caused by:\n",
            "    chromadb 0.5.5 depends on chroma-hnswlib==0.7.6\n",
            "    chromadb 0.5.4 depends on pypika>=0.48.9\n",
            "    chromadb 0.5.3 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.5.2 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.5.1 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.5.0 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.24 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.23 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.22 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.21 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.20 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.19 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.18 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.17 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.16 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.15 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.14 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.13 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.12 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.11 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.10 depends on chroma-hnswlib==0.7.3\n",
            "    chromadb 0.4.9 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.8 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.7 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.6 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.5 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.4 depends on chroma-hnswlib==0.7.2\n",
            "    chromadb 0.4.3 depends on chroma-hnswlib==0.7.1\n",
            "    chromadb 0.4.2 depends on chroma-hnswlib==0.7.1\n",
            "    chromadb 0.4.1 depends on chroma-hnswlib==0.7.1\n",
            "    chromadb 0.4.0 depends on chroma-hnswlib==0.7.1\n",
            "    chromadb 0.3.29 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.27 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.26 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.25 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.23 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.22 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.21 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.20 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.18 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.17 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.16 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.15 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.14 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.13 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.12 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.11 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.10 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.8 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.7 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.6 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.5 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.4 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.3 depends on hnswlib>=0.7\n",
            "    chromadb 0.3.2 depends on pandas~=1.3\n",
            "    chromadb 0.3.1 depends on pandas~=1.3\n",
            "    chromadb 0.3.0 depends on pandas~=1.3\n",
            "    chromadb 0.2.0 depends on pandas~=1.3\n",
            "    chromadb 0.1.0 depends on pandas~=1.3\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Cannot install chromadb==0.1.0, chromadb==0.2.0, chromadb==0.3.0, chromadb==0.3.1, chromadb==0.3.10, chromadb==0.3.11, chromadb==0.3.12, chromadb==0.3.13, chromadb==0.3.14, chromadb==0.3.15, chromadb==0.3.16, chromadb==0.3.17, chromadb==0.3.18, chromadb==0.3.2, chromadb==0.3.20, chromadb==0.3.21, chromadb==0.3.22, chromadb==0.3.23, chromadb==0.3.25, chromadb==0.3.26, chromadb==0.3.27, chromadb==0.3.29, chromadb==0.3.3, chromadb==0.3.4, chromadb==0.3.5, chromadb==0.3.6, chromadb==0.3.7, chromadb==0.3.8, chromadb==0.4.0, chromadb==0.4.1, chromadb==0.4.10, chromadb==0.4.11, chromadb==0.4.12, chromadb==0.4.13, chromadb==0.4.14, chromadb==0.4.15, chromadb==0.4.16, chromadb==0.4.17, chromadb==0.4.18, chromadb==0.4.19, chromadb==0.4.2, chromadb==0.4.20, chromadb==0.4.21, chromadb==0.4.22, chromadb==0.4.23, chromadb==0.4.24, chromadb==0.4.3, chromadb==0.4.4, chromadb==0.4.5, chromadb==0.4.6, chromadb==0.4.7, chromadb==0.4.8, chromadb==0.4.9, chromadb==0.5.0, chromadb==0.5.1, chromadb==0.5.2, chromadb==0.5.3, chromadb==0.5.4 and chromadb==0.5.5 because these package versions have conflicting dependencies.\n",
            "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
          ]
        }
      ],
      "source": [
        "! pip install --only-binary=:all: chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in d:\\rag\\venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in d:\\rag\\venv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
            "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/14.6 MB 5.6 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 1.0/14.6 MB 7.2 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 1.8/14.6 MB 3.1 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 2.4/14.6 MB 3.1 MB/s eta 0:00:05\n",
            "   ------- -------------------------------- 2.9/14.6 MB 2.9 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 3.1/14.6 MB 2.8 MB/s eta 0:00:05\n",
            "   ---------- ----------------------------- 3.7/14.6 MB 2.6 MB/s eta 0:00:05\n",
            "   ---------- ----------------------------- 3.9/14.6 MB 2.6 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 4.5/14.6 MB 2.5 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 5.0/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 5.2/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 5.8/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 6.3/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 6.8/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 7.3/14.6 MB 2.4 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 7.9/14.6 MB 2.4 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 8.1/14.6 MB 2.4 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 8.7/14.6 MB 2.4 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 9.2/14.6 MB 2.4 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 9.7/14.6 MB 2.4 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 10.5/14.6 MB 2.4 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 11.0/14.6 MB 2.4 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 11.5/14.6 MB 2.4 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 12.1/14.6 MB 2.4 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 12.6/14.6 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 13.4/14.6 MB 2.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 13.9/14.6 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.4/14.6 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.6/14.6 MB 2.5 MB/s eta 0:00:00\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ],
      "source": [
        "! pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0NWFLsiQkDlD"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "vectorstore = FAISS.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
        "\n",
        "retrieved_docs = retriever.invoke(\"What is new in yolov9?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g1pb4m5TkDn3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(retrieved_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nation of steps including pretrained by ImageNet, knowl-\n",
            "edge distillation, DAMO-YOLO and even additional pre-\n",
            "trained large object detection dataset. We show the results\n",
            "in Table 3. From this table, we can see that our proposed\n",
            "YOLOv9 performed better than all other methods. Com-\n",
            "pared with PPYOLOE+-X trained using ImageNet and Ob-\n",
            "jects365, our method still reduces the number of parame-\n",
            "ters by 55% and the amount of computation by 11%, and\n",
            "improving 0.4% AP.\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(retrieved_docs[8].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.3, max_tokens=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PlainNet is a type of deep neural network architecture. PlainNets are characterized by their simple sequential structure, where layers are stacked on top of each other without any skip connections or complex modules. Due to this simple design, PlainNets tend to lose important information in deep layers, making them less effective for tasks like object detection as the network grows deeper. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"what is plainnet?\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
